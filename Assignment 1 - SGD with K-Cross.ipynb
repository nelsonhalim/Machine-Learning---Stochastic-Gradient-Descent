{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer Perceptron with Stochastic Gradient Descent with K-Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading the data set and taking only 2 classes\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('irisdata.csv',header=None)\n",
    "\n",
    "data = data[data[4] != 'Iris-versicolor']\n",
    "data[4] = data[4].str.replace('Iris-setosa','1')\n",
    "data[4] = data[4].str.replace('Iris-virginica','0')\n",
    "data[4] = data[4].astype('int64')\n",
    "array_data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialisations of variables\n",
    "epoch = 60\n",
    "\n",
    "alpha = 0.1\n",
    "theta = np.array([0.2,0.3,0.3,0.2])\n",
    "bias = 0.3\n",
    "\n",
    "d_bias = 0\n",
    "h = 0\n",
    "array_dtheta = np.empty(4)\n",
    "total_error = np.zeros(epoch)\n",
    "\n",
    "total_error_train = np.zeros(epoch)\n",
    "total_error_val = np.zeros(epoch)\n",
    "\n",
    "local_error_train = 0\n",
    "local_error_val = 0\n",
    "\n",
    "total_error_train1 = np.zeros(epoch)\n",
    "total_error_val1 = np.zeros(epoch)\n",
    "\n",
    "total_error_train2 = np.zeros(epoch)\n",
    "total_error_val2 = np.zeros(epoch)\n",
    "\n",
    "total_error_train3 = np.zeros(epoch)\n",
    "total_error_val3 = np.zeros(epoch)\n",
    "\n",
    "total_error_train4 = np.zeros(epoch)\n",
    "total_error_val4 = np.zeros(epoch)\n",
    "\n",
    "total_error_train5 = np.zeros(epoch)\n",
    "total_error_val5 = np.zeros(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from random import seed\n",
    "# from random import randrange\n",
    " \n",
    "# # Split a dataset into k folds\n",
    "# def cross_validation_split(dataset, folds=5):\n",
    "#     dataset_split = list()\n",
    "#     dataset_copy = list(dataset)\n",
    "#     fold_size = int(len(dataset) / folds)\n",
    "#     for i in range(folds):\n",
    "#         fold = list()\n",
    "#         while len(fold) < fold_size:\n",
    "#             index = randrange(len(dataset_copy))\n",
    "#             fold.append(dataset_copy.pop(index))\n",
    "#         dataset_split.append(fold)\n",
    "#     return dataset_split\n",
    " \n",
    "# # test cross validation split\n",
    "# seed(1)\n",
    "# dataset = array_data\n",
    "# folds = cross_validation_split(dataset, 5)\n",
    "# folds[0]\n",
    "\n",
    "# def k_fold_cross_validation(X, K, randomise = False):\n",
    "# \t\"\"\"\n",
    "# \tGenerates K (training, validation) pairs from the items in X.\n",
    "\n",
    "# \tEach pair is a partition of X, where validation is an iterable\n",
    "# \tof length len(X)/K. So each training iterable is of length (K-1)*len(X)/K.\n",
    "\n",
    "# \tIf randomise is true, a copy of X is shuffled before partitioning,\n",
    "# \totherwise its order is preserved in training and validation.\n",
    "# \t\"\"\"\n",
    "# \tif randomise: from random import shuffle; X=list(X); shuffle(X)\n",
    "# \tfor k in list(range(K)):\n",
    "# \t\ttraining = [x for i, x in enumerate(X) if i % K != k]\n",
    "# \t\tvalidation = [x for i, x in enumerate(X) if i % K == k]\n",
    "# \t\tyield training, validation\n",
    "\n",
    "# X = [i for i in list(range(97))]\n",
    "# for training, validation in k_fold_cross_validation(X, K=5):\n",
    "# \tfor x in X: assert (x in training) ^ (x in validation), x\n",
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fold1 = pd.DataFrame(folds[0])\n",
    "# fold2 = pd.DataFrame(folds[1])\n",
    "# fold3 = pd.DataFrame(folds[2])\n",
    "# fold4 = pd.DataFrame(folds[3])\n",
    "# fold5 = pd.DataFrame(folds[4])\n",
    "\n",
    "# fold1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dividing the dataset into k folds\n",
    "fold_11 = pd.read_csv('irisdata.csv', header=None, nrows=10)\n",
    "fold_12 = pd.read_csv('irisdata.csv', header=None, skiprows=100, nrows=10)\n",
    "fold1 = pd.concat([fold_11,fold_12])\n",
    "fold1[4] = fold1[4].str.replace('Iris-setosa','1')\n",
    "fold1[4] = fold1[4].str.replace('Iris-virginica','0')\n",
    "fold1[4] = fold1[4].astype('int64')\n",
    "\n",
    "fold_21 = pd.read_csv('irisdata.csv', header=None, skiprows=10,nrows=10)\n",
    "fold_22 = pd.read_csv('irisdata.csv', header=None, skiprows=110, nrows=10)\n",
    "fold2 = pd.concat([fold_21,fold_22])\n",
    "fold2[4] = fold2[4].str.replace('Iris-setosa','1')\n",
    "fold2[4] = fold2[4].str.replace('Iris-virginica','0')\n",
    "fold2[4] = fold2[4].astype('int64')\n",
    "\n",
    "fold_31 = pd.read_csv('irisdata.csv', header=None, skiprows=20,nrows=10)\n",
    "fold_32 = pd.read_csv('irisdata.csv', header=None, skiprows=120, nrows=10)\n",
    "fold3 = pd.concat([fold_31,fold_32])\n",
    "fold3[4] = fold3[4].str.replace('Iris-setosa','1')\n",
    "fold3[4] = fold3[4].str.replace('Iris-virginica','0')\n",
    "fold3[4] = fold3[4].astype('int64')\n",
    "\n",
    "fold_41 = pd.read_csv('irisdata.csv', header=None, skiprows=30,nrows=10)\n",
    "fold_42 = pd.read_csv('irisdata.csv', header=None, skiprows=130, nrows=10)\n",
    "fold4 = pd.concat([fold_41,fold_42])\n",
    "fold4[4] = fold4[4].str.replace('Iris-setosa','1')\n",
    "fold4[4] = fold4[4].str.replace('Iris-virginica','0')\n",
    "fold4[4] = fold4[4].astype('int64')\n",
    "\n",
    "fold_51 = pd.read_csv('irisdata.csv', header=None, skiprows=40,nrows=10)\n",
    "fold_52 = pd.read_csv('irisdata.csv', header=None, skiprows=140, nrows=10)\n",
    "fold5 = pd.concat([fold_51,fold_52])\n",
    "fold5[4] = fold5[4].str.replace('Iris-setosa','1')\n",
    "fold5[4] = fold5[4].str.replace('Iris-virginica','0')\n",
    "fold5[4] = fold5[4].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fold5 as validation\n",
    "train1 = pd.concat([fold1,fold2,fold3,fold4])\n",
    "val1 = fold5\n",
    "\n",
    "#Fold4 as validation\n",
    "train2 = pd.concat([fold1,fold2,fold3,fold5])\n",
    "val2 = fold4\n",
    "\n",
    "#Fold3 as validation\n",
    "train3 = pd.concat([fold1,fold2,fold4,fold5])\n",
    "val3 = fold3\n",
    "\n",
    "#Fold2 as validation\n",
    "train4 = pd.concat([fold1,fold3,fold4,fold5])\n",
    "val4 = fold2\n",
    "\n",
    "#Fold1 as validation\n",
    "train5 = pd.concat([fold2,fold3,fold4,fold5])\n",
    "val5 = fold1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining functions\n",
    "import math as mt\n",
    "\n",
    "def h(x,theta,bias,n):\n",
    "    return np.dot(x.iloc[n,:4],np.transpose(theta)) + bias\n",
    "\n",
    "def sigmoid(h):\n",
    "    return 1/(1+mt.exp(-h))\n",
    "\n",
    "def error(data,sigmoid,n):\n",
    "    return (sigmoid-data.iloc[n,4])**2\n",
    "\n",
    "def prediction(sigmoid):\n",
    "    if sigmoid >= 0.5:\n",
    "        prediction = 1\n",
    "        return prediction\n",
    "    else:\n",
    "        prediction = 0\n",
    "        return prediction\n",
    "\n",
    "def d_theta(sigmoid,fact,x_array,i):\n",
    "    return 2*(sigmoid-fact)*(1-sigmoid)*sigmoid*x_array[i]\n",
    "\n",
    "def d_bias(sigmoid,fact):\n",
    "    return 2*(sigmoid-fact)*(1-sigmoid)*sigmoid\n",
    "\n",
    "def new_theta(theta,alpha,d_theta,i):\n",
    "    return theta[i]-(alpha*d_theta[i])\n",
    "\n",
    "def new_bias(bias,alpha,d_bias):\n",
    "    return bias-(alpha*d_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculations\n",
    "\n",
    "for n in range(epoch):\n",
    "    \n",
    "    \"\"\"Fold5 as validation\"\"\"\n",
    "    temp1_theta = np.zeros(4)\n",
    "    temp1_bias = 0\n",
    "    \n",
    "    for i in range(len(train1)):\n",
    "\n",
    "        x_array = np.array(train1.iloc[i,:4]) #x1234\n",
    "\n",
    "        fact = train1.iloc[i,4]\n",
    "\n",
    "        h_value = h(train1,theta,bias,i)\n",
    "\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "\n",
    "        error_value = error(train1,sigmoid_value,i)\n",
    "\n",
    "        local_error_train = local_error_train + error_value\n",
    "            \n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "         \n",
    "        for j in range(len(x_array)):\n",
    "            array_dtheta[j] = d_theta(sigmoid_value,fact,x_array,j)\n",
    "\n",
    "        d_bias_value = d_bias(sigmoid_value,fact)\n",
    "        \n",
    "        for j in range(len(theta)):\n",
    "            theta[j] = new_theta(theta,alpha,array_dtheta,j)\n",
    "        temp1_theta = theta\n",
    "        \n",
    "        new_bias_value = new_bias(bias,alpha,d_bias_value)\n",
    "        bias = new_bias_value\n",
    "        temp1_bias = bias\n",
    "        \n",
    "    total_error_train1[n] = ((local_error_train) / (len(train1)))\n",
    "    local_error_train = 0\n",
    "    \n",
    "    for i in range(len(val1)):\n",
    "    \n",
    "        x_array = np.array(val1.iloc[i,:4])\n",
    "        \n",
    "        fact = val1.iloc[i,4]\n",
    "        \n",
    "        h_value = h(val1,temp1_theta,temp1_bias,i)\n",
    "        \n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        \n",
    "        error_value = error(val1,sigmoid_value,i)\n",
    "        local_error_val = local_error_val + error_value\n",
    "        \n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "        \n",
    "    total_error_val1[n] = ((local_error_val) / (len(val1)))\n",
    "    local_error_val = 0\n",
    "    \n",
    "    \"\"\"Fold4 as validation\"\"\"\n",
    "    temp2_theta = np.zeros(4)\n",
    "    temp2_bias = 0\n",
    "    \n",
    "    for i in range(len(train2)):\n",
    "        \n",
    "        x_array = np.array(train2.iloc[i,:4])\n",
    "        fact = train2.iloc[i,4]\n",
    "        h_value = h(train2,theta,bias,i)\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        error_value = error(train2,sigmoid_value,i)   \n",
    "        local_error_train = local_error_train + error_value\n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "        for j in range(len(x_array)):\n",
    "            array_dtheta[j] = d_theta(sigmoid_value,fact,x_array,j)\n",
    "        d_bias_value = d_bias(sigmoid_value,fact)\n",
    "        for j in range(len(theta)):\n",
    "            theta[j] = new_theta(theta,alpha,array_dtheta,j)\n",
    "        temp2_theta = theta\n",
    "        new_bias_value = new_bias(bias,alpha,d_bias_value)\n",
    "        bias = new_bias_value\n",
    "        temp2_bias = bias\n",
    "    total_error_train2[n] = ((local_error_train) / (len(train2)))\n",
    "    local_error_train = 0\n",
    "    \n",
    "    for i in range(len(val2)):\n",
    "    \n",
    "        x_array = np.array(val2.iloc[i,:4])\n",
    "        fact = val2.iloc[i,4]\n",
    "        h_value = h(val2,temp2_theta,temp2_bias,i)\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        error_value = error(val2,sigmoid_value,i)\n",
    "        local_error_val = local_error_val + error_value\n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "    \n",
    "    total_error_val2[n] = ((local_error_val / (len(val2))))\n",
    "    local_error_val = 0\n",
    "    \n",
    "    \n",
    "    \"\"\"Fold3 as validation\"\"\"\n",
    "    temp3_theta = np.zeros(4)\n",
    "    temp3_bias = 0\n",
    "    \n",
    "    for i in range(len(train3)):\n",
    "        \n",
    "        x_array = np.array(train3.iloc[i,:4])\n",
    "        fact = train3.iloc[i,4]\n",
    "        h_value = h(train3,theta,bias,i)\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        error_value = error(train3,sigmoid_value,i)   \n",
    "        local_error_train = local_error_train + error_value\n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "        for j in range(len(x_array)):\n",
    "            array_dtheta[j] = d_theta(sigmoid_value,fact,x_array,j)\n",
    "        d_bias_value = d_bias(sigmoid_value,fact)\n",
    "        for j in range(len(theta)):\n",
    "            theta[j] = new_theta(theta,alpha,array_dtheta,j)\n",
    "        temp3_theta = theta\n",
    "        new_bias_value = new_bias(bias,alpha,d_bias_value)\n",
    "        bias = new_bias_value\n",
    "        temp3_bias = bias\n",
    "    total_error_train3[n] = ((local_error_train) / (len(train3)))\n",
    "    local_error_train = 0\n",
    "    \n",
    "    for i in range(len(val3)):\n",
    "    \n",
    "        x_array = np.array(val3.iloc[i,:4])\n",
    "        fact = val3.iloc[i,4]\n",
    "        h_value = h(val3,temp3_theta,temp3_bias,i)\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        error_value = error(val3,sigmoid_value,i)\n",
    "        local_error_val = local_error_val + error_value\n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "    \n",
    "    total_error_val3[n] = ((local_error_val) / (len(val3)))\n",
    "    local_error_val = 0\n",
    "    \n",
    "    \"\"\"Fold2 as validation\"\"\"\n",
    "    temp4_theta = np.zeros(4)\n",
    "    temp4_bias = 0\n",
    "    \n",
    "    for i in range(len(train4)):\n",
    "        \n",
    "        x_array = np.array(train4.iloc[i,:4])\n",
    "        fact = train4.iloc[i,4]\n",
    "        h_value = h(train4,theta,bias,i)\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        error_value = error(train4,sigmoid_value,i)   \n",
    "        local_error_train = local_error_train + error_value\n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "        for j in range(len(x_array)):\n",
    "            array_dtheta[j] = d_theta(sigmoid_value,fact,x_array,j)\n",
    "        d_bias_value = d_bias(sigmoid_value,fact)\n",
    "        for j in range(len(theta)):\n",
    "            theta[j] = new_theta(theta,alpha,array_dtheta,j)\n",
    "        temp4_theta = theta\n",
    "        new_bias_value = new_bias(bias,alpha,d_bias_value)\n",
    "        bias = new_bias_value\n",
    "        temp4_bias = bias\n",
    "    total_error_train4[n] = ((local_error_train) / (len(train4)))\n",
    "    local_error_train = 0\n",
    "    \n",
    "    for i in range(len(val4)):\n",
    "    \n",
    "        x_array = np.array(val4.iloc[i,:4])\n",
    "        fact = val4.iloc[i,4]\n",
    "        h_value = h(val4,temp4_theta,temp4_bias,i)\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        error_value = error(val4,sigmoid_value,i)\n",
    "        local_error_val = local_error_val + error_value\n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "    \n",
    "    total_error_val4[n] = ((local_error_val) / (len(val4)))\n",
    "    local_error_val = 0\n",
    "    \n",
    "    \"\"\"Fold1 as validation\"\"\"\n",
    "    temp5_theta = np.zeros(4)\n",
    "    temp5_bias = 0\n",
    "    \n",
    "    for i in range(len(train5)):\n",
    "        \n",
    "        x_array = np.array(train5.iloc[i,:4])\n",
    "        fact = train5.iloc[i,4]\n",
    "        h_value = h(train5,theta,bias,i)\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        error_value = error(train5,sigmoid_value,i)   \n",
    "        local_error_train = local_error_train + error_value\n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "        for j in range(len(x_array)):\n",
    "            array_dtheta[j] = d_theta(sigmoid_value,fact,x_array,j)\n",
    "        d_bias_value = d_bias(sigmoid_value,fact)\n",
    "        for j in range(len(theta)):\n",
    "            theta[j] = new_theta(theta,alpha,array_dtheta,j)\n",
    "        temp5_theta = theta\n",
    "        new_bias_value = new_bias(bias,alpha,d_bias_value)\n",
    "        bias = new_bias_value\n",
    "        temp5_bias = bias\n",
    "    total_error_train5[n] = ((local_error_train) / (len(train5)))\n",
    "    local_error_train = 0\n",
    "    \n",
    "    for i in range(len(val5)):\n",
    "    \n",
    "        x_array = np.array(val5.iloc[i,:4])\n",
    "        fact = val5.iloc[i,4]\n",
    "        h_value = h(val5,temp5_theta,temp5_bias,i)\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        error_value = error(val5,sigmoid_value,i)\n",
    "        local_error_val = local_error_val + error_value\n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "    \n",
    "    total_error_val5[n] = ((local_error_val) / (len(val5)))\n",
    "    local_error_val = 0\n",
    "    \n",
    "    #Summing all training and validation errors\n",
    "    total_error_train[n] = np.add(np.add(np.add(total_error_train1[n],total_error_train2[n]),np.add(total_error_train3[n],total_error_train4[n])),total_error_train5[n])\n",
    "    total_error_val[n] = np.add(np.add(np.add(total_error_val1[n],total_error_val2[n]),np.add(total_error_val3[n],total_error_val4[n])),total_error_val5[n])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUZCIiEhB/j/HWvqn3w3jggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bf69f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualisations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot((total_error_train3), color=\"blue\")\n",
    "plt.plot(total_error_val3, color= \"red\")\n",
    "plt.legend([\"Data Training\", \"Data Validation\"])\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.9951580635 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = (1 - (total_error_val[59]/5)) * 100\n",
    "print(accuracy,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
