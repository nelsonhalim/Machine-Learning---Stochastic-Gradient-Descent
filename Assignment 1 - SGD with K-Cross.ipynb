{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer Perceptron with Stochastic Gradient Descent with K-Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading the data set and taking only 2 classes\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('irisdata.csv',header=None)\n",
    "\n",
    "data = data[data[4] != 'Iris-versicolor']\n",
    "data[4] = data[4].str.replace('Iris-setosa','1')\n",
    "data[4] = data[4].str.replace('Iris-virginica','0')\n",
    "data[4] = data[4].astype('int64')\n",
    "array_data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisations of variables\n",
    "epoch = 60\n",
    "\n",
    "alpha = 0.1\n",
    "theta = np.array([0.2,0.3,0.3,0.2])\n",
    "bias = 0.3\n",
    "\n",
    "d_bias = 0\n",
    "h = 0\n",
    "array_dtheta = np.empty(4)\n",
    "total_error = np.zeros(epoch)\n",
    "\n",
    "total_error_train = np.zeros(epoch)\n",
    "total_error_val = np.zeros(epoch)\n",
    "\n",
    "local_error_train = 0\n",
    "local_error_val = 0\n",
    "\n",
    "total_error_train1 = np.zeros(epoch)\n",
    "total_error_val1 = np.zeros(epoch)\n",
    "\n",
    "total_error_train2 = np.zeros(epoch)\n",
    "total_error_val2 = np.zeros(epoch)\n",
    "\n",
    "total_error_train3 = np.zeros(epoch)\n",
    "total_error_val3 = np.zeros(epoch)\n",
    "\n",
    "total_error_train4 = np.zeros(epoch)\n",
    "total_error_val4 = np.zeros(epoch)\n",
    "\n",
    "total_error_train5 = np.zeros(epoch)\n",
    "total_error_val5 = np.zeros(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from random import seed\n",
    "# from random import randrange\n",
    " \n",
    "# # Split a dataset into k folds\n",
    "# def cross_validation_split(dataset, folds=5):\n",
    "#     dataset_split = list()\n",
    "#     dataset_copy = list(dataset)\n",
    "#     fold_size = int(len(dataset) / folds)\n",
    "#     for i in range(folds):\n",
    "#         fold = list()\n",
    "#         while len(fold) < fold_size:\n",
    "#             index = randrange(len(dataset_copy))\n",
    "#             fold.append(dataset_copy.pop(index))\n",
    "#         dataset_split.append(fold)\n",
    "#     return dataset_split\n",
    " \n",
    "# # test cross validation split\n",
    "# seed(1)\n",
    "# dataset = array_data\n",
    "# folds = cross_validation_split(dataset, 5)\n",
    "# folds[0]\n",
    "\n",
    "# def k_fold_cross_validation(X, K, randomise = False):\n",
    "# \t\"\"\"\n",
    "# \tGenerates K (training, validation) pairs from the items in X.\n",
    "\n",
    "# \tEach pair is a partition of X, where validation is an iterable\n",
    "# \tof length len(X)/K. So each training iterable is of length (K-1)*len(X)/K.\n",
    "\n",
    "# \tIf randomise is true, a copy of X is shuffled before partitioning,\n",
    "# \totherwise its order is preserved in training and validation.\n",
    "# \t\"\"\"\n",
    "# \tif randomise: from random import shuffle; X=list(X); shuffle(X)\n",
    "# \tfor k in list(range(K)):\n",
    "# \t\ttraining = [x for i, x in enumerate(X) if i % K != k]\n",
    "# \t\tvalidation = [x for i, x in enumerate(X) if i % K == k]\n",
    "# \t\tyield training, validation\n",
    "\n",
    "# X = [i for i in list(range(97))]\n",
    "# for training, validation in k_fold_cross_validation(X, K=5):\n",
    "# \tfor x in X: assert (x in training) ^ (x in validation), x\n",
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold1 = pd.DataFrame(folds[0])\n",
    "# fold2 = pd.DataFrame(folds[1])\n",
    "# fold3 = pd.DataFrame(folds[2])\n",
    "# fold4 = pd.DataFrame(folds[3])\n",
    "# fold5 = pd.DataFrame(folds[4])\n",
    "\n",
    "# fold1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing the dataset into k folds\n",
    "fold_11 = pd.read_csv('irisdata.csv', header=None, nrows=10)\n",
    "fold_12 = pd.read_csv('irisdata.csv', header=None, skiprows=100, nrows=10)\n",
    "fold1 = pd.concat([fold_11,fold_12])\n",
    "fold1[4] = fold1[4].str.replace('Iris-setosa','1')\n",
    "fold1[4] = fold1[4].str.replace('Iris-virginica','0')\n",
    "fold1[4] = fold1[4].astype('int64')\n",
    "\n",
    "fold_21 = pd.read_csv('irisdata.csv', header=None, skiprows=10,nrows=10)\n",
    "fold_22 = pd.read_csv('irisdata.csv', header=None, skiprows=110, nrows=10)\n",
    "fold2 = pd.concat([fold_21,fold_22])\n",
    "fold2[4] = fold2[4].str.replace('Iris-setosa','1')\n",
    "fold2[4] = fold2[4].str.replace('Iris-virginica','0')\n",
    "fold2[4] = fold2[4].astype('int64')\n",
    "\n",
    "fold_31 = pd.read_csv('irisdata.csv', header=None, skiprows=20,nrows=10)\n",
    "fold_32 = pd.read_csv('irisdata.csv', header=None, skiprows=120, nrows=10)\n",
    "fold3 = pd.concat([fold_31,fold_32])\n",
    "fold3[4] = fold3[4].str.replace('Iris-setosa','1')\n",
    "fold3[4] = fold3[4].str.replace('Iris-virginica','0')\n",
    "fold3[4] = fold3[4].astype('int64')\n",
    "\n",
    "fold_41 = pd.read_csv('irisdata.csv', header=None, skiprows=30,nrows=10)\n",
    "fold_42 = pd.read_csv('irisdata.csv', header=None, skiprows=130, nrows=10)\n",
    "fold4 = pd.concat([fold_41,fold_42])\n",
    "fold4[4] = fold4[4].str.replace('Iris-setosa','1')\n",
    "fold4[4] = fold4[4].str.replace('Iris-virginica','0')\n",
    "fold4[4] = fold4[4].astype('int64')\n",
    "\n",
    "fold_51 = pd.read_csv('irisdata.csv', header=None, skiprows=40,nrows=10)\n",
    "fold_52 = pd.read_csv('irisdata.csv', header=None, skiprows=140, nrows=10)\n",
    "fold5 = pd.concat([fold_51,fold_52])\n",
    "fold5[4] = fold5[4].str.replace('Iris-setosa','1')\n",
    "fold5[4] = fold5[4].str.replace('Iris-virginica','0')\n",
    "fold5[4] = fold5[4].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fold5 as validation\n",
    "train1 = pd.concat([fold1,fold2,fold3,fold4])\n",
    "val1 = fold5\n",
    "\n",
    "#Fold4 as validation\n",
    "train2 = pd.concat([fold1,fold2,fold3,fold5])\n",
    "val2 = fold4\n",
    "\n",
    "#Fold3 as validation\n",
    "train3 = pd.concat([fold1,fold2,fold4,fold5])\n",
    "val3 = fold3\n",
    "\n",
    "#Fold2 as validation\n",
    "train4 = pd.concat([fold1,fold3,fold4,fold5])\n",
    "val4 = fold2\n",
    "\n",
    "#Fold1 as validation\n",
    "train5 = pd.concat([fold2,fold3,fold4,fold5])\n",
    "val5 = fold1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining functions\n",
    "import math as mt\n",
    "\n",
    "def h(x,theta,bias,n):\n",
    "    return np.dot(x.iloc[n,:4],np.transpose(theta)) + bias\n",
    "\n",
    "def sigmoid(h):\n",
    "    return 1/(1+mt.exp(-h))\n",
    "\n",
    "def error(data,sigmoid,n):\n",
    "    return (sigmoid-data.iloc[n,4])**2\n",
    "\n",
    "def prediction(sigmoid):\n",
    "    if sigmoid >= 0.5:\n",
    "        prediction = 1\n",
    "        return prediction\n",
    "    else:\n",
    "        prediction = 0\n",
    "        return prediction\n",
    "\n",
    "def d_theta(sigmoid,fact,x_array,i):\n",
    "    return 2*(sigmoid-fact)*(1-sigmoid)*sigmoid*x_array[i]\n",
    "\n",
    "def d_bias(sigmoid,fact):\n",
    "    return 2*(sigmoid-fact)*(1-sigmoid)*sigmoid\n",
    "\n",
    "def new_theta(theta,alpha,d_theta,i):\n",
    "    return theta[i]-(alpha*d_theta[i])\n",
    "\n",
    "def new_bias(bias,alpha,d_bias):\n",
    "    return bias-(alpha*d_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculations\n",
    "\n",
    "for n in range(epoch):\n",
    "    \n",
    "    \"\"\"Fold5 as validation\"\"\"\n",
    "    temp1_theta = np.zeros(4)\n",
    "    temp1_bias = 0\n",
    "    \n",
    "    for i in range(len(train1)):\n",
    "\n",
    "        x_array = np.array(train1.iloc[i,:4]) #x1234\n",
    "\n",
    "        fact = train1.iloc[i,4]\n",
    "\n",
    "        h_value = h(train1,theta,bias,i)\n",
    "\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "\n",
    "        error_value = error(train1,sigmoid_value,i)\n",
    "\n",
    "        local_error_train = local_error_train + error_value\n",
    "            \n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "         \n",
    "        for j in range(len(x_array)):\n",
    "            array_dtheta[j] = d_theta(sigmoid_value,fact,x_array,j)\n",
    "\n",
    "        d_bias_value = d_bias(sigmoid_value,fact)\n",
    "        \n",
    "        for j in range(len(theta)):\n",
    "            theta[j] = new_theta(theta,alpha,array_dtheta,j)\n",
    "        temp1_theta = theta\n",
    "        \n",
    "        new_bias_value = new_bias(bias,alpha,d_bias_value)\n",
    "        bias = new_bias_value\n",
    "        temp1_bias = bias\n",
    "        \n",
    "    total_error_train1[n] = ((local_error_train) / (len(train1)))\n",
    "    local_error_train = 0\n",
    "    \n",
    "    for i in range(len(val1)):\n",
    "    \n",
    "        x_array = np.array(val1.iloc[i,:4])\n",
    "        \n",
    "        fact = val1.iloc[i,4]\n",
    "        \n",
    "        h_value = h(val1,temp1_theta,temp1_bias,i)\n",
    "        \n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        \n",
    "        error_value = error(val1,sigmoid_value,i)\n",
    "        local_error_val = local_error_val + error_value\n",
    "        \n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "        \n",
    "    total_error_val1[n] = ((local_error_val) / (len(val1)))\n",
    "    local_error_val = 0\n",
    "    \n",
    "    \"\"\"Fold4 as validation\"\"\"\n",
    "    temp2_theta = np.zeros(4)\n",
    "    temp2_bias = 0\n",
    "    \n",
    "    for i in range(len(train2)):\n",
    "        \n",
    "        x_array = np.array(train2.iloc[i,:4])\n",
    "        fact = train2.iloc[i,4]\n",
    "        h_value = h(train2,theta,bias,i)\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        error_value = error(train2,sigmoid_value,i)   \n",
    "        local_error_train = local_error_train + error_value\n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "        for j in range(len(x_array)):\n",
    "            array_dtheta[j] = d_theta(sigmoid_value,fact,x_array,j)\n",
    "        d_bias_value = d_bias(sigmoid_value,fact)\n",
    "        for j in range(len(theta)):\n",
    "            theta[j] = new_theta(theta,alpha,array_dtheta,j)\n",
    "        temp2_theta = theta\n",
    "        new_bias_value = new_bias(bias,alpha,d_bias_value)\n",
    "        bias = new_bias_value\n",
    "        temp2_bias = bias\n",
    "    total_error_train2[n] = ((local_error_train) / (len(train2)))\n",
    "    local_error_train = 0\n",
    "    \n",
    "    for i in range(len(val2)):\n",
    "    \n",
    "        x_array = np.array(val2.iloc[i,:4])\n",
    "        fact = val2.iloc[i,4]\n",
    "        h_value = h(val2,temp2_theta,temp2_bias,i)\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        error_value = error(val2,sigmoid_value,i)\n",
    "        local_error_val = local_error_val + error_value\n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "    \n",
    "    total_error_val2[n] = ((local_error_val / (len(val2))))\n",
    "    local_error_val = 0\n",
    "    \n",
    "    \n",
    "    \"\"\"Fold3 as validation\"\"\"\n",
    "    temp3_theta = np.zeros(4)\n",
    "    temp3_bias = 0\n",
    "    \n",
    "    for i in range(len(train3)):\n",
    "        \n",
    "        x_array = np.array(train3.iloc[i,:4])\n",
    "        fact = train3.iloc[i,4]\n",
    "        h_value = h(train3,theta,bias,i)\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        error_value = error(train3,sigmoid_value,i)   \n",
    "        local_error_train = local_error_train + error_value\n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "        for j in range(len(x_array)):\n",
    "            array_dtheta[j] = d_theta(sigmoid_value,fact,x_array,j)\n",
    "        d_bias_value = d_bias(sigmoid_value,fact)\n",
    "        for j in range(len(theta)):\n",
    "            theta[j] = new_theta(theta,alpha,array_dtheta,j)\n",
    "        temp3_theta = theta\n",
    "        new_bias_value = new_bias(bias,alpha,d_bias_value)\n",
    "        bias = new_bias_value\n",
    "        temp3_bias = bias\n",
    "    total_error_train3[n] = ((local_error_train) / (len(train3)))\n",
    "    local_error_train = 0\n",
    "    \n",
    "    for i in range(len(val3)):\n",
    "    \n",
    "        x_array = np.array(val3.iloc[i,:4])\n",
    "        fact = val3.iloc[i,4]\n",
    "        h_value = h(val3,temp3_theta,temp3_bias,i)\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        error_value = error(val3,sigmoid_value,i)\n",
    "        local_error_val = local_error_val + error_value\n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "    \n",
    "    total_error_val3[n] = ((local_error_val) / (len(val3)))\n",
    "    local_error_val = 0\n",
    "    \n",
    "    \"\"\"Fold2 as validation\"\"\"\n",
    "    temp4_theta = np.zeros(4)\n",
    "    temp4_bias = 0\n",
    "    \n",
    "    for i in range(len(train4)):\n",
    "        \n",
    "        x_array = np.array(train4.iloc[i,:4])\n",
    "        fact = train4.iloc[i,4]\n",
    "        h_value = h(train4,theta,bias,i)\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        error_value = error(train4,sigmoid_value,i)   \n",
    "        local_error_train = local_error_train + error_value\n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "        for j in range(len(x_array)):\n",
    "            array_dtheta[j] = d_theta(sigmoid_value,fact,x_array,j)\n",
    "        d_bias_value = d_bias(sigmoid_value,fact)\n",
    "        for j in range(len(theta)):\n",
    "            theta[j] = new_theta(theta,alpha,array_dtheta,j)\n",
    "        temp4_theta = theta\n",
    "        new_bias_value = new_bias(bias,alpha,d_bias_value)\n",
    "        bias = new_bias_value\n",
    "        temp4_bias = bias\n",
    "    total_error_train4[n] = ((local_error_train) / (len(train4)))\n",
    "    local_error_train = 0\n",
    "    \n",
    "    for i in range(len(val4)):\n",
    "    \n",
    "        x_array = np.array(val4.iloc[i,:4])\n",
    "        fact = val4.iloc[i,4]\n",
    "        h_value = h(val4,temp4_theta,temp4_bias,i)\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        error_value = error(val4,sigmoid_value,i)\n",
    "        local_error_val = local_error_val + error_value\n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "    \n",
    "    total_error_val4[n] = ((local_error_val) / (len(val4)))\n",
    "    local_error_val = 0\n",
    "    \n",
    "    \"\"\"Fold1 as validation\"\"\"\n",
    "    temp5_theta = np.zeros(4)\n",
    "    temp5_bias = 0\n",
    "    \n",
    "    for i in range(len(train5)):\n",
    "        \n",
    "        x_array = np.array(train5.iloc[i,:4])\n",
    "        fact = train5.iloc[i,4]\n",
    "        h_value = h(train5,theta,bias,i)\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        error_value = error(train5,sigmoid_value,i)   \n",
    "        local_error_train = local_error_train + error_value\n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "        for j in range(len(x_array)):\n",
    "            array_dtheta[j] = d_theta(sigmoid_value,fact,x_array,j)\n",
    "        d_bias_value = d_bias(sigmoid_value,fact)\n",
    "        for j in range(len(theta)):\n",
    "            theta[j] = new_theta(theta,alpha,array_dtheta,j)\n",
    "        temp5_theta = theta\n",
    "        new_bias_value = new_bias(bias,alpha,d_bias_value)\n",
    "        bias = new_bias_value\n",
    "        temp5_bias = bias\n",
    "    total_error_train5[n] = ((local_error_train) / (len(train5)))\n",
    "    local_error_train = 0\n",
    "    \n",
    "    for i in range(len(val5)):\n",
    "    \n",
    "        x_array = np.array(val5.iloc[i,:4])\n",
    "        fact = val5.iloc[i,4]\n",
    "        h_value = h(val5,temp5_theta,temp5_bias,i)\n",
    "        sigmoid_value = sigmoid(h_value)\n",
    "        error_value = error(val5,sigmoid_value,i)\n",
    "        local_error_val = local_error_val + error_value\n",
    "        prediction_value = prediction(sigmoid_value)\n",
    "    \n",
    "    total_error_val5[n] = ((local_error_val) / (len(val5)))\n",
    "    local_error_val = 0\n",
    "    \n",
    "    #Summing all training and validation errors\n",
    "    total_error_train[n] = np.add(np.add(np.add(total_error_train1[n],total_error_train2[n]),np.add(total_error_train3[n],total_error_train4[n])),total_error_train5[n])\n",
    "    total_error_val[n] = np.add(np.add(np.add(total_error_val1[n],total_error_val2[n]),np.add(total_error_val3[n],total_error_val4[n])),total_error_val5[n])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119ce6be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualisations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot((total_error_train5), color=\"blue\")\n",
    "plt.plot(total_error_val5, color= \"red\")\n",
    "plt.legend([\"Data Training\", \"Data Validation\"])\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
